{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Tutorial for Training & Deploying Image Classification Model using module twin update\n",
    "* Train using custom dataset to detect soda pepsi/coke cans\n",
    "* Convert trained model to IR -> Blob using Intel open vino toolkit \n",
    "* Deploy Model to the devkit using module twin update method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting up cloud environment\n",
    "!pip install azureml-core azureml-contrib-iot azure-mgmt-containerregistry\n",
    "!az extension add --name azure-cli-iot-ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.__file__)\n",
    "#Import python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core as azcore\n",
    "\n",
    "print(\"SDK version:\", azcore.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a Workspace, if it does not exist\n",
    "#### Update the values for your ML workspace below\n",
    "from azureml.core import Workspace\n",
    "ws=Workspace.create(subscription_id='<subscriptionid>',\n",
    "                resource_group='<Resourcegroup>',\n",
    "                name='<MLWorkspace>',\n",
    "                location='<Location>')\n",
    "                \n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Workspace \n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Experiment\n",
    "Experiment is a logical container in an Azure ML Workspace. It hosts run records which can include run metrics and output artifacts from your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'soda_cans'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace = ws, name = experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data\n",
    "### Option 1: Upload data files into datastore\n",
    "Every workspace comes with a default datastore (and you can register more) which is backed by the Azure blob storage account associated with the workspace. We can use it to transfer data from local to the cloud, and access it from the compute target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = experiment_name + '_training_data'\n",
    "ds.upload(src_dir='data/soda_cans', target_path=data_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Use existing datastore in Azure blob storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from azureml.core.datastore import Datastore\n",
    "ds = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                         datastore_name='xxx', \n",
    "                                         container_name='xxx',\n",
    "                                         account_name='xxxx', \n",
    "                                         account_key='xxx',\n",
    "                                         create_if_not_exists=False)\n",
    "data_path = \"soda_cans_training_data\" # This is the path to the folder in the blob container. Set this to None to get all the contents.\n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure for using ACI\n",
    "\n",
    "Linux-based ACI is available in West US, East US, West Europe, North Europe, West US 2, Southeast Asia, Australia East, East US 2, and Central US regions.  See details [here](https://docs.microsoft.com/en-us/azure/container-instances/container-instances-quotas#region-availability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Represents configuration for experiment that runs targeting different compute targets in Azure Machine Learning. The RunConfiguration object encapsulates the information necessary to submit a training run in an experiment.\n",
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "dr = DataReferenceConfiguration(datastore_name=ds.name, \n",
    "                   path_on_datastore=data_path, \n",
    "                   mode='download', # download files from datastore to compute target\n",
    "                   overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the system to build a conda environment based on the run configuration. Once the environment is built, and if you don't change your dependencies, it will be reused in subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"cpucluster1\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_D3', max_nodes=2)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# Use the 'status' property to get a detailed status for the current AmlCompute. \n",
    "print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To create a GPU cluster, run the cell below. Note that your subscription must have sufficient quota for GPU VMs or the command will fail. To increase quota, see these instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your GPU cluster\n",
    "gpu_cluster_name = \"gpucluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    gpu_cluster = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
    "    print(\"Found existing gpu cluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new gpucluster\")\n",
    "    \n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\",\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=4)\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\n",
    "\n",
    "    # Wait for the cluster to complete, show the output log\n",
    "    gpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up dependencies\n",
    "from azureml.core.runconfig import RunConfiguration, DEFAULT_CPU_IMAGE\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_pip_package(\"tensorflow==1.8.0\")\n",
    "myenv.add_pip_package(\"azureml-defaults\")\n",
    "myenv.add_pip_package(\"keras\")\n",
    "\n",
    "with open(\"myenv.yml\", \"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "\n",
    "with open(\"myenv.yml\", \"r\") as f:\n",
    "    print(f.read())\n",
    "    \n",
    "# create a new runconfig object\n",
    "run_config = RunConfiguration(framework = \"python\")\n",
    "\n",
    "# Set compute target\n",
    "run_config.target = compute_target.name\n",
    "\n",
    "# set the data reference of the run configuration\n",
    "run_config.data_references = {ds.name: dr}\n",
    "\n",
    "# enable Docker \n",
    "run_config.environment.docker.enabled = True\n",
    "\n",
    "# set Docker base image to the default CPU-based image\n",
    "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "\n",
    "# use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# auto-prepare the Docker image when used for execution (if it is not already prepared) -- deprecated\n",
    "#run_config.auto_prepare_environment = True\n",
    "\n",
    "# specify CondaDependencies obj\n",
    "#run_config.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['tensorflow==1.8.0'])\n",
    "run_config.environment.python.conda_dependencies = myenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the Experiment\n",
    "Submit script to run in the Docker image in the remote VM. If you run this for the first time, the system will download the base image, layer in packages specified in the conda_dependencies.yml file on top of the base image, create a container and then execute the script in the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from azureml.core import Run\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "src = ScriptRunConfig(source_directory = './02-mobilenet-transfer-learning-scripts', script = 'retrain.py', run_config = run_config, \n",
    "                      # pass the datastore reference as a parameter to the training script\n",
    "                      arguments=['--image_dir', str(ds.as_download()),\n",
    "                                 '--architecture', 'mobilenet_1.0_224',\n",
    "                                 '--output_graph', 'outputs/retrained_graph.pb',\n",
    "                                 '--output_labels', 'outputs/output_labels.txt',\n",
    "                                 '--model_download_url', 'https://raw.githubusercontent.com/rakelkar/models/master/model_output/',\n",
    "                                 '--model_file_name', 'imagenet_2_frozen.pb'\n",
    "                                ])\n",
    "run = exp.submit(config=src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_path = \"outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the retrained model and the labels locally\n",
    "run.download_file(name = 'outputs/retrained_graph.pb', output_file_path = trained_model_path)\n",
    "run.download_file(name = 'outputs/labels.txt', output_file_path = trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = trained_model_path,\n",
    "                      model_name = \"<ModelName>\",\n",
    "                      tags = {\"<data>\": \"<Imagenet>\", \"<model>\": \"<object_detection>\", \"<type>\": \"<imagenet>\"},\n",
    "                      description = \"<Model Description>\",\n",
    "                      workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "### Convert the trained model to IR -> Blob using Intel Openvino toolkit for running on Devkit running Myriadx chipset\n",
    "1) Setup Intel openvino toolkit on local machine https://docs.openvinotoolkit.org/latest/openvino_docs_install_guides_installing_openvino_windows.html\n",
    "2) Download the retrained_graph.pb, config.json and labels.txt from the notebook vm /outputs folder to local machine\n",
    "3) Model conversion to IR and Blob. Run the command from the command prompt as administrator\n",
    "python \"c:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_ty.py\" --input_model C:\\ICModels\\retrained_graph.pb --input_shape (1,224,224,3) --data_type FP16\n",
    "    \n",
    "\"C:\\Program Files (x86)\\IntelSWTools\\openvino_2020.3.194\\deployment_tools\\inference_engine\\bin\\intel64\\Release\\myriad_compile.exe\" -m retrained_graph.xml -ip U8 -VPU_MYRIAD_PLATFORM VPU_MYRIAD_2480 -VPU_NUMBER_OF_SHAVES 8 -VPU_NUMBER_OF_CMX_SLICES 8 -o mobilenetv1.blob -op FP32\n",
    "\n",
    "4) zip mobilenetv1.blob, labels.txt and config.json to mobilenetv1.zip\n",
    "5) Upload the zip to /ouput1 folder in notebook vm\n",
    "6) Next step is to push the model to devkit using module twin update method\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Modelpath'\n",
    "ds.upload(src_dir='./output1', target_path=data_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generated Saas url for module twin update\n",
    "from azure.storage.blob.baseblobservice import BaseBlobService,BlobPermissions\n",
    "#from azure.storage.blob import BlobPermissions\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "AZURE_ACC_NAME = ds.account_name\n",
    "AZURE_PRIMARY_KEY = ds.account_key\n",
    "AZURE_CONTAINER = ds.container_name\n",
    "AZURE_BLOB=ds.name\n",
    "AZURE_File=data_path+'/mobilenetv1.zip'\n",
    "\n",
    "service = BaseBlobService(account_name=AZURE_ACC_NAME, account_key=AZURE_PRIMARY_KEY)\n",
    "sas_url  = service.generate_blob_shared_access_signature(AZURE_CONTAINER,AZURE_File,permission=BlobPermissions.READ,expiry= datetime.utcnow() + timedelta(hours=2))\n",
    "#sas_url = block_blob_service.generate_blob_shared_access_signature(AZURE_CONTAINER,AZURE_File,permission=BlobPermissions.READ,expiry= datetime.utcnow() + timedelta(hours=48))\n",
    "\n",
    "#block_blob_service = BlockBlobService(account_name=AZURE_ACC_NAME, account_key=AZURE_PRIMARY_KEY)\n",
    "#sas_url = block_blob_service.generate_blob_shared_access_signature(AZURE_CONTAINER,AZURE_File,permission=BlobPermissions.READ,expiry= datetime.utcnow() + timedelta(hours=48))\n",
    "downloadurl ='https://'+AZURE_ACC_NAME+'.blob.core.windows.net/'+AZURE_CONTAINER+'/'+AZURE_File+'?'+sas_url\n",
    "print('https://'+AZURE_ACC_NAME+'.blob.core.windows.net/'+AZURE_CONTAINER+'/'+AZURE_File+'?'+sas_url)\n",
    "print(sas_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Module twin update\n",
    "#Incorporate the connection string, device_id and the module_id values from your IoTHub\n",
    "\n",
    "!pip install azure-iot-hub\n",
    "import sys\n",
    "from azure.iot.hub import IoTHubRegistryManager\n",
    "from azure.iot.hub.models import Twin, TwinProperties\n",
    "\n",
    "#Incorporate Iothub connection string and the default module name\n",
    "#Go to Https://portal.azure.com\n",
    "#Select your IoTHub\n",
    "#Click on Shared access policies\n",
    "#Click service on right\n",
    "#Copy the iothub connection string primary key\n",
    "#Device id is the device name\n",
    "\n",
    "CONNECTION_STRING = \"<IOTHUB connection string>\"\n",
    "DEVICE_ID = '<DeviceID>'\n",
    "MODULE_ID = \"azureeyemodule\"\n",
    "\n",
    "try:\n",
    "    # RegistryManager\n",
    "    iothub_registry_manager = IoTHubRegistryManager(CONNECTION_STRING)\n",
    "\n",
    "    module_twin = iothub_registry_manager.get_module_twin(DEVICE_ID, MODULE_ID)\n",
    "    print ( \"\" )\n",
    "    print ( \"Module twin properties before update    :\" )\n",
    "    print ( \"{0}\".format(module_twin.properties) )\n",
    "\n",
    "    # Update twin\n",
    "    twin_patch = Twin()\n",
    "    twin_patch.properties = TwinProperties(desired={\"ModelZipUrl\": downloadurl})\n",
    "    updated_module_twin = iothub_registry_manager.update_module_twin(\n",
    "        DEVICE_ID, MODULE_ID, twin_patch, module_twin.etag\n",
    "    )\n",
    "    print ( \"\" )\n",
    "    print ( \"Module twin properties after update     :\" )\n",
    "    print ( \"{0}\".format(updated_module_twin.properties) )\n",
    "\n",
    "except Exception as ex:\n",
    "    print ( \"Unexpected error {0}\".format(ex) )\n",
    "except KeyboardInterrupt:\n",
    "    print ( \"IoTHubRegistryManager sample stopped\" )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#sodacan custom model has been pushed to IoT Hub using module twin update and will be deployed to the devkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The trained model will get pushed to the IoT Edge device via module twin update method\n",
    "# Check model inferencing by connecting monitor to the devkit or by installing VLC media player : \n",
    "#Install VLC from https://www.videolan.org/vlc/ and install on “Windows” to check the camera function of “Azure Eye”.\n",
    "\n",
    "#Check video stream:\n",
    "#1.\tSelect Media -> Open Network Stream…\n",
    "#2.\tInput the network stream: “rtsp://[ip of PE-101]:8554/result” then click “Play” button.\n",
    "#3. or use webstream streaming http://<ipaddressofcamera>:3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# delete cpu compute\n",
    "\"\"\"\n",
    "mycompute = AmlCompute(workspace=ws, name='cpucluster1')\n",
    "mycompute.delete()\n",
    "\n",
    "# delete gpu compute\n",
    "mycompute = AmlCompute(workspace=ws, name='gpucluster1')\n",
    "mycompute.delete()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# delete workspace\n",
    "#ws.delete(delete_dependent_resources=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
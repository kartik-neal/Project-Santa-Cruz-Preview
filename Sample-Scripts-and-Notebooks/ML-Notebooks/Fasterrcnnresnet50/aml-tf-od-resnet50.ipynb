{"cells":[{"cell_type":"code","source":["Copyright (c) Microsoft Corporation. All rights reserved.\r\n","\r\n","Licensed under the MIT License."],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Object Detection transfer learning using tensorflow Faster_rcnn_resnet101 model on Azure ML"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Build tensorflow object detection docker image for AzureML\r\n","#Specify your docker container registry (<ACR_NAME>.azurecr.io) and the repo name (dw-tf-od:v1). You can go to https://portal.azure.com and go to container registry to find your container details or create new one. \r\n","import docker\r\n","!docker build --tag <ACR_NAME>.azurecr.io/dw-tf-od:v1 './docker'"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["!az login"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Authenticate to container\r\n","!az acr login -n <ACR_NAME>"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Push docker image to Azure container registry which will then be used for transfer learning training\r\n","!docker push <ACR_NAME>.azurecr.io/dw-tf-od:v1"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Setup workspace\n","import azureml.core\n","from azureml.core import Workspace\n","print(azureml.core.VERSION)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["import azureml.core\n","print(\"SDK version:\", azureml.core.VERSION)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["#Collecting telmetry for the experiment\n","#from azureml.telemetry import set_diagnostics_collection\n","#set_diagnostics_collection(send_diagnostics=True)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["# Include your subscription, resource_group and the workspace details which will be used for experiment runs. This will create the workspace, if it doesn't exist\n","subscription_id = <subscriptionid>\n","resource_group = <Resoucegroup>\n","workspace_name = <workspace>\n","loc=<location>\n","\n","# create aml workspace or create it azure portal\n","#https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py#workspace\n","\n","from azureml.core import Workspace\n","ws = Workspace.create(name=workspace_name,\n","                      subscription_id=subscription_id,\n","                      resource_group=resource_group,\n","                      create_resource_group=True,\n","                      location=loc\n","                     )"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["#Capture your Azure container registry details\n","\n","acr_server = \"<ACR_NAME.azurecr.io\"\n","acr_login = \"ACR_NAME\"\n","acr_pwd = \"<PWD>\"\n","#acr_repo_name = \"dw-tf-od:v1-gpu\"\n","acr_repo_name = \"dw-tf-od:v1\""],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["#Reload workspace details for training\n","\n","from azureml.core import Workspace\n","\n","ws = Workspace.from_config()\n","ws.get_details()"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["# setup datastore for loading custom labelled datasets\n","# For this training the data set was labelled using https://github.com/Microsoft/VoTT tool\n","ds = ws.get_default_datastore()\n","ds.name"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["# Load data folder to default storage datastore\n","ds.upload(\n","    src_dir='./upload_data',\n","    target_path='tfdata',\n","    overwrite=True)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["\"\"\"\n","# train remote VM - gpu\n","from azureml.core.compute import AmlCompute, ComputeTarget\n","from azureml.core.compute_target import ComputeTargetException\n","\n","try:\n","    compute_target = ComputeTarget(workspace=ws, name='dw-gpu')\n","    print('found existing:', compute_target.name)\n","except ComputeTargetException:\n","    print('creating new.')\n","    compute_config = AmlCompute.provisioning_configuration(\n","        vm_size='STANDARD_NC6',\n","        min_nodes=0,\n","        max_nodes=1)\n","    compute_target = ComputeTarget.create(ws, 'dw-gpu', compute_config)\n","    compute_target.wait_for_completion(show_output=True)\n","\"\"\""],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["# train remote VM - cpu\n","from azureml.core.compute import AmlCompute, ComputeTarget\n","from azureml.core.compute_target import ComputeTargetException\n","\n","try:\n","    compute_target = ComputeTarget(workspace=ws, name='dw-cpu1')\n","    print('found existing:', compute_target.name)\n","except ComputeTargetException:\n","    print('creating new.')\n","    compute_config = AmlCompute.provisioning_configuration(\n","        vm_size='STANDARD_D3_V2',\n","        min_nodes=0,\n","        max_nodes=1)\n","    compute_target = ComputeTarget.create(ws, 'dw-cpu1', compute_config)\n","    compute_target.wait_for_completion(show_output=True)\n"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["# Mounting the uploaded data for training\n","from azureml.core import Datastore\n","from azureml.core.runconfig import DataReferenceConfiguration\n","\n","ds = ws.get_default_datastore()\n","\n","dr_conf = DataReferenceConfiguration(\n","    datastore_name=ds.name,\n","    path_on_datastore='tfdata',\n","    #path_on_compute = '/tfdata'\n","    mode='mount') # or 'download'"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["\"\"\"\r\n","# data reference using storage download (optional)\r\n","from azureml.core import Datastore\r\n","from azureml.core.runconfig import DataReferenceConfiguration\r\n","\r\n","ds = Datastore.get(ws, datastore_name=\"workspaceblobstore\")\r\n","\r\n","dr_conf = DataReferenceConfiguration(\r\n","    datastore_name=ds.name,\r\n","    path_on_datastore='tfdata',\r\n","    #path_on_compute = '/tfdata'\r\n","    mode='download') # or 'mount'\r\n","\"\"\""],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["'''\r\n","# use estimator with download paramer (optional)\r\n","# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training-with-deep-learning/distributed-cntk-with-custom-docker/distributed-cntk-with-custom-docker.ipynb\r\n","from azureml.train.estimator import Estimator\r\n","\r\n","#params= {'--data_folder' : ds.as_download() }\r\n","\r\n","params= {'--data_folder' : ds.as_download(),'--output_dir': './outputs'}\r\n","\r\n","estimator = Estimator(source_directory='script',\r\n","                      compute_target=compute_target,\r\n","                      entry_script='train.py',\r\n","                      script_params=params,\r\n","                      node_count=1,\r\n","                      process_count_per_node=1,\r\n","                      pip_requirements_file = '../docker/requirements.txt', # pip packages\r\n","                      custom_docker_image='<ACR_NAME>.azurecr.io/dw-tf-od:v1', # using public docker hub\r\n","                      use_gpu=False)\r\n","                      \r\n","'''"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# Running experiment using Estimator\r\n","# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training-with-deep-learning/distributed-cntk-with-custom-docker/distributed-cntk-with-custom-docker.ipynb\r\n","from azureml.train.estimator import Estimator\r\n","\r\n","params= {'--data_folder' : ds.as_mount() }\r\n","\r\n","estimator = Estimator(source_directory='script',\r\n","                      compute_target=compute_target,\r\n","                      #compute_target='local',\r\n","                      entry_script='train.py',\r\n","                      script_params=params,\r\n","                      node_count=1,\r\n","                      process_count_per_node=1,\r\n","                      pip_requirements_file = '../docker/requirements.txt', # pip packages\r\n","                      custom_docker_image='<ACR_NAME>.azurecr.io/dw-tf-od:v1', # using public docker hub\r\n","                      use_gpu=False)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core import Experiment\n","\n","experiment_name = 'dw-exp-resnet50'\n","experiment = Experiment(ws, name=experiment_name)\n","\n","run = experiment.submit(estimator)\n","print(run)\n","\n","run.wait_for_completion(show_output=True)"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["#The trained model is stored from Experiment run in the Experiment -> Output+Logs tab. "],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["'''\r\n","#Get the best model\r\n","minimum_rmse_runid = None\r\n","minimum_rmse = None\r\n","\r\n","for run in experiment.get_runs():\r\n","    run_metrics = run.get_metrics()\r\n","    run_details = run.get_details()\r\n","    # each logged metric becomes a key in this returned dict\r\n","    run_rmse = run_metrics[\"\"]\r\n","    run_id = run_details[\"\"]\r\n","\r\n","    if minimum_rmse is None:\r\n","        minimum_rmse = run_rmse\r\n","        minimum_rmse_runid = run_id\r\n","    else:\r\n","        if run_rmse < minimum_rmse:\r\n","            minimum_rmse = run_rmse\r\n","            minimum_rmse_runid = run_id\r\n","\r\n","print(\"Best run_id: \" + minimum_rmse_runid)\r\n","print(\"Best run_id rmse: \" + str(minimum_rmse))\r\n","'''"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["'''\r\n","from azureml.core import Run\r\n","best_run = Run(experiment=experiment, run_id=minimum_rmse_runid)\r\n","print(best_run.get_file_names())\r\n","'''"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Reload workspace details for module twin update\r\n","\r\n","from azureml.core import Workspace\r\n","\r\n","ws = Workspace.from_config()\r\n","ws.get_details()"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Register the trained model. Once register you'll find the model in the Models section on the left pane\r\n","from azureml.core.model import Model\r\n","\r\n","model = Model.register(model_path = trained_model_path,\r\n","                      model_name = \"Forks_Scissors_resnet50\",\r\n","                      tags = {\"data\": \"faster_rcnn_resnet50\", \"model\": \"object_detection\", \"type\": \"faster_rcnn_resnet50\"},\r\n","                      description = \"Retrained Forks Scissors based on faster_rcnn_resnet50\",\r\n","                      workspace = ws)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["'''\r\n","### Convert the trained model to IR -> Blob using Intel Openvino toolkit for running on Devkit running Myriadx chipset\r\n","1) Setup Intel openvino toolkit on local machine https://docs.openvinotoolkit.org/latest/openvino_docs_install_guides_installing_openvino_windows.html\r\n","2) Download the Frozen_inference_graph.pb model file, pipeline.config, labels.txt and config.json from the notebook vm /outputs folder to local machine for model conversion\r\n","3) Model conversion to IR and Blob. Run the command from the command prompt as administrator\r\n","Pb->IR\r\n","python \"c:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py\"  --input_model frozen_inference_graph.pb --tensorflow_object_detection_api_pipeline_config pipeline.config --transformations_config   \"C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\extensions\\front\\tf\\ssd_v2_support.json\" \r\n","\r\n","IR->Blob\r\n","\"C:\\Program Files (x86)\\IntelSWTools\\openvino_2020.3.194\\deployment_tools\\inference_engine\\bin\\intel64\\Release\\myriad_compile.exe\" -m frozen_inference_graph.xml -o fast-rcnn-resnet50.blob -VPU_MYRIAD_PLATFORM VPU_MYRIAD_2480 -VPU_NUMBER_OF_SHAVES 8 -VPU_NUMBER_OF_CMX_SLICES 8 -iop \"image_tensor:U8, image_info:FP32\" -op FP32\r\n","4) If you trained with your custom data set, make sure to update the labels.txt with the classes used for training\r\n","5) Zip the converted model file .blob, labels.txt and config.json to model_resnet50.zip and upload the zip file to /ouputs/convertedmodel folder in notebook vm\r\n","6) Next step is to upload the zip file to blobstore and push it to the devkit using module twin update\r\n","'''"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Reload workspace details for module twin update\r\n","\r\n","from azureml.core import Workspace\r\n","\r\n","ws = Workspace.from_config()\r\n","ws.get_details()"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# get the default datastore\r\n","ds = ws.get_default_datastore()\r\n","print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#set data path for model.zip\r\n","data_path = 'modelpath'\r\n","ds.upload(src_dir='./outputs/convertedmodel', target_path=data_path, overwrite=True)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Generated Saas url for module twin update\r\n","from azure.storage.blob.baseblobservice import BaseBlobService,BlobPermissions\r\n","#from azure.storage.blob import BlobPermissions\r\n","from datetime import datetime, timedelta\r\n","\r\n","AZURE_ACC_NAME = ds.account_name\r\n","AZURE_PRIMARY_KEY = ds.account_key\r\n","AZURE_CONTAINER = ds.container_name\r\n","AZURE_BLOB=ds.name\r\n","AZURE_File=data_path+'/model_resnet50.zip'\r\n","\r\n","service = BaseBlobService(account_name=AZURE_ACC_NAME, account_key=AZURE_PRIMARY_KEY)\r\n","sas_url  = service.generate_blob_shared_access_signature(AZURE_CONTAINER,AZURE_File,permission=BlobPermissions.READ,expiry= datetime.utcnow() + timedelta(hours=48))\r\n","#sas_url = block_blob_service.generate_blob_shared_access_signature(AZURE_CONTAINER,AZURE_File,permission=BlobPermissions.READ,expiry= datetime.utcnow() + timedelta(hours=48))\r\n","\r\n","#block_blob_service = BlockBlobService(account_name=AZURE_ACC_NAME, account_key=AZURE_PRIMARY_KEY)\r\n","#sas_url = block_blob_service.generate_blob_shared_access_signature(AZURE_CONTAINER,AZURE_File,permission=BlobPermissions.READ,expiry= datetime.utcnow() + timedelta(hours=48))\r\n","downloadurl ='https://'+AZURE_ACC_NAME+'.blob.core.windows.net/'+AZURE_CONTAINER+'/'+AZURE_File+'?'+sas_url\r\n","print('https://'+AZURE_ACC_NAME+'.blob.core.windows.net/'+AZURE_CONTAINER+'/'+AZURE_File+'?'+sas_url)\r\n","print(sas_url)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Perform Module twin update\r\n","#Incorporate the connection string, device_id and the module_id values from your IoTHub\r\n","\r\n","!pip install azure-iot-hub\r\n","import sys\r\n","from azure.iot.hub import IoTHubRegistryManager\r\n","from azure.iot.hub.models import Twin, TwinProperties\r\n","\r\n","#Incorporate Iothub connection string and the default module name\r\n","#Go to Https://portal.azure.com\r\n","#Select your IoTHub\r\n","#Click on Shared access policies\r\n","#click service on right\r\n","#Copy the iothub connection string primary key\r\n","\r\n","CONNECTION_STRING = \"<IOTHUBConnection string>\"\r\n","DEVICE_ID = '<Device_ID>'\r\n","MODULE_ID = \"azureeyemodule\"\r\n","\r\n","try:\r\n","    # RegistryManager\r\n","    iothub_registry_manager = IoTHubRegistryManager(CONNECTION_STRING)\r\n","\r\n","    module_twin = iothub_registry_manager.get_module_twin(DEVICE_ID, MODULE_ID)\r\n","    print ( \"\" )\r\n","    print ( \"Module twin properties before update    :\" )\r\n","    print ( \"{0}\".format(module_twin.properties) )\r\n","\r\n","    # Update twin\r\n","    twin_patch = Twin()\r\n","    twin_patch.properties = TwinProperties(desired={\"ModelZipUrl\": downloadurl})\r\n","    updated_module_twin = iothub_registry_manager.update_module_twin(\r\n","        DEVICE_ID, MODULE_ID, twin_patch, module_twin.etag\r\n","    )\r\n","    print ( \"\" )\r\n","    print ( \"Module twin properties after update     :\" )\r\n","    print ( \"{0}\".format(updated_module_twin.properties) )\r\n","\r\n","except Exception as ex:\r\n","    print ( \"Unexpected error {0}\".format(ex) )\r\n","except KeyboardInterrupt:\r\n","    print ( \"IoTHubRegistryManager sample stopped\" )"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# The trained model will get pushed to the IoT Edge device via module twin update method\r\n","# Check model inferencing by connecting monitor to the devkit or by installing VLC media player : \r\n","#Install VLC from https://www.videolan.org/vlc/ and install on “Windows” to check the camera function of “Azure Eye”.\r\n","\r\n","#Check video stream:\r\n","#1.\tSelect Media -> Open Network Stream…\r\n","#2.\tInput the network stream: “rtsp://[ip of PE-101]:8554/result” then click “Play” button."],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Environment Cleanup\r\n","#Check the docker image id created for the acr repo name\r\n","#!docker images"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Delete docker registry by uncommenting the below step and including the image id\r\n","#!docker rmi -f <imageid>"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# delete cpu compute\n","\"\"\"\n","mycompute = AmlCompute(workspace=ws, name='dw-cpu1')\n","mycompute.delete()\n","\n","# delete gpu compute\n","mycompute = AmlCompute(workspace=ws, name='dw-gpu')\n","mycompute.delete()\n","\"\"\""],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["# delete workspace\n","#ws.delete(delete_dependent_resources=True)\n"],"outputs":[],"execution_count":null,"metadata":{}}],"metadata":{"kernelspec":{"name":"python3-azureml","language":"python","display_name":"Python 3.6 - AzureML"},"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"nteract":{"version":"nteract-front-end@1.0.0"},"kernel_info":{"name":"python3-azureml"}},"nbformat":4,"nbformat_minor":4}